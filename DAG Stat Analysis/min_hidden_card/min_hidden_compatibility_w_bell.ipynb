{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structural Equation Test to the Bell DAG:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "given Bell scenario correlations\n",
    "$P(A,B,X,Y) =  \\sum_\\lambda P(A| X, \\lambda) P(B|Y, \\lambda) P(X)P(Y)P(\\lambda) \\qquad \\forall \\lambda \\in $ [0,card_l] our goal is to find the smallest integer $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File structure\n",
    "1) Generating compatible distributions with deterministic strategies\n",
    "2) Checking compatibility of given distribution via deterministic strategies\n",
    "3) Checking compatibility of given distribution via structural equation\n",
    "4) Finding minimal cardinality of hidden classical variable $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "from gurobipy import GRB, norm\n",
    "import itertools\n",
    "import numpy as np\n",
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Generating compatible distributions with deterministic strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "card_A, card_B, card_X, card_Y = 2, 2, 2, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_bell_dist_det():\n",
    "\n",
    "    ## Bin(INT), Bin(INT) -> Bin(INT)\n",
    "    def identity(x):\n",
    "        return x\n",
    "    def swap(x):\n",
    "        return 1-x\n",
    "    def to0(_):\n",
    "        return 0\n",
    "    def to1(_):\n",
    "        return 1\n",
    "\n",
    "    basic_strategies = [identity, swap, to0, to1]\n",
    "    all_strategies = list(itertools.product(basic_strategies, repeat=2))\n",
    "    def generate_top(u):\n",
    "        f_u, g_u = all_strategies[u]\n",
    "\n",
    "        # value 1 at point(a,b) = (f_u(x),g_u(y)), zero everywhere else\n",
    "        def middle_entry(x,y):\n",
    "            # value 1 at (f_u(x),g_u(y)) zero everywhere else\n",
    "            middle = np.zeros((2,2), dtype=int)\n",
    "            middle[f_u(x), g_u(y)] = 1\n",
    "            return middle\n",
    "\n",
    "        top_level = np.array([\n",
    "                    [middle_entry(0,0), middle_entry(0,1)], \n",
    "                    [middle_entry(1,0), middle_entry(1,1)]\n",
    "                    ]) \n",
    "\n",
    "        return top_level\n",
    "\n",
    "    # multiplying the summed weights by a random number between 0 and 1\n",
    "    arr = sum([np.random.rand()*generate_top(i) for i in range(16)])\n",
    "    for x,y in np.ndindex(2,2):\n",
    "        sum_values = np.sum(arr[x, y])\n",
    "        arr[x, y] /= sum_values # normalization\n",
    "    # print(np.sum(arr))\n",
    "\n",
    "    # have in appropriate dictionary form\n",
    "    P_AB_giv_XY_dict = {}\n",
    "    for a,b,x,y in np.ndindex(2,2,2,2):\n",
    "        P_AB_giv_XY_dict[(a,b,x,y)] = arr[x][y][a][b]\n",
    "    # print(P_AB_giv_XY_dict)\n",
    "    # arr\n",
    "    return P_AB_giv_XY_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a random distribution for P_l with given cardinality ######\n",
    "def hidden_dist(cardL):\n",
    "    rand_numbs = np.random.random(cardL)\n",
    "    normd_numbs = rand_numbs / np.sum(rand_numbs)\n",
    "    scaled_numbs = np.round(normd_numbs * 10**3) / 10**3\n",
    "    correction = 1 - np.sum(scaled_numbs)\n",
    "    largest_index = np.argmax(scaled_numbs)\n",
    "    scaled_numbs[largest_index] += correction\n",
    "    return scaled_numbs\n",
    "\n",
    "def sample_bell_dist_cond_prob():\n",
    "    cardL = 7\n",
    "    distribution_sampled = []\n",
    "    while len(distribution_sampled)<1:\n",
    "        P_l = hidden_dist(cardL)\n",
    "        P_A_giv_Xl = np.empty((card_A, card_X, cardL))\n",
    "        P_B_giv_Yl = np.empty((card_B, card_Y, cardL))\n",
    "        for x, l in np.ndindex((card_X, cardL)):\n",
    "            P_A_giv_Xl[:,x,l] = hidden_dist(card_A)\n",
    "        for y, l in np.ndindex((card_Y, cardL)):\n",
    "            P_B_giv_Yl[:,y,l] = hidden_dist(card_B)\n",
    "        P_A_do_X = (P_A_giv_Xl * P_l.reshape((1,1,cardL))).sum(axis=2)\n",
    "        P_B_do_Y = (P_B_giv_Yl * P_l.reshape((1,1,cardL))).sum(axis=2)\n",
    "        if not np.all(np.abs(P_A_do_X[:,0]-P_A_do_X[:,1]) > 0.2):\n",
    "            continue\n",
    "        if not np.all(np.abs(P_B_do_Y[:,0]-P_B_do_Y[:,1]) > 0.2):\n",
    "            continue\n",
    "        P_ABL_giv_XY = P_l.reshape((1,1,1,1,cardL)) * P_A_giv_Xl.reshape((card_A,1,card_X,1,cardL))  * P_B_giv_Yl.reshape((1,card_B,1,card_Y,cardL)) \n",
    "        P_AB_giv_XY = P_ABL_giv_XY.sum(axis=4)\n",
    "        distribution_sampled.append(P_AB_giv_XY)\n",
    "        # for x, y in np.ndindex((card_X, card_Y)):\n",
    "        #     print(P_AB_giv_XY[:,:,x,y])\n",
    "\n",
    "    # in dictionary format\n",
    "    print(P_AB_giv_XY[a,b,x,y][0])\n",
    "    # P_AB_giv_XY_dict = {(a,b,x,y): P_AB_giv_XY[a,b,x,y][0] for a,b,x,y in itertools.product(range(2), repeat=4)}\n",
    "    # return P_AB_giv_XY_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a random distribution for P_l with given cardinality ######\n",
    "def hidden_dist(cardL):\n",
    "    rand_numbs = np.random.random(cardL)\n",
    "    normd_numbs = rand_numbs / np.sum(rand_numbs)\n",
    "    scaled_numbs = np.round(normd_numbs * 10**3) / 10**3\n",
    "    correction = 1 - np.sum(scaled_numbs)\n",
    "    largest_index = np.argmax(scaled_numbs)\n",
    "    scaled_numbs[largest_index] += correction\n",
    "    return scaled_numbs\n",
    "\n",
    "def sample_bell_dist_cond_prob():\n",
    "    cardL = 7\n",
    "    distribution_sampled = []\n",
    "    while len(distribution_sampled)<1:\n",
    "        P_l = hidden_dist(cardL)\n",
    "        P_A_giv_Xl = np.empty((card_A, card_X, cardL))\n",
    "        P_B_giv_Yl = np.empty((card_B, card_Y, cardL))\n",
    "        for x, l in np.ndindex((card_X, cardL)):\n",
    "            P_A_giv_Xl[:,x,l] = hidden_dist(card_A)\n",
    "        for y, l in np.ndindex((card_Y, cardL)):\n",
    "            P_B_giv_Yl[:,y,l] = hidden_dist(card_B)\n",
    "        P_A_do_X = (P_A_giv_Xl * P_l.reshape((1,1,cardL))).sum(axis=2)\n",
    "        P_B_do_Y = (P_B_giv_Yl * P_l.reshape((1,1,cardL))).sum(axis=2)\n",
    "        if not np.all(np.abs(P_A_do_X[:,0]-P_A_do_X[:,1]) > 0.2):\n",
    "            continue\n",
    "        if not np.all(np.abs(P_B_do_Y[:,0]-P_B_do_Y[:,1]) > 0.2):\n",
    "            continue\n",
    "        P_ABL_giv_XY = P_l.reshape((1,1,1,1,cardL)) * P_A_giv_Xl.reshape((card_A,1,card_X,1,cardL))  * P_B_giv_Yl.reshape((1,card_B,1,card_Y,cardL)) \n",
    "        P_AB_giv_XY = P_ABL_giv_XY.sum(axis=4)\n",
    "        distribution_sampled.append(P_AB_giv_XY)\n",
    "        # for x, y in np.ndindex((card_X, card_Y)):\n",
    "        #     print(P_AB_giv_XY[:,:,x,y])\n",
    "\n",
    "    # in dictionary format\n",
    "    P_AB_giv_XY_dict = {(a,b,x,y): P_AB_giv_XY[a,b,x,y] for a,b,x,y in itertools.product(range(2), repeat=4)}\n",
    "    return P_AB_giv_XY_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(0, 0, 0, 0): 0.40872569099999995,\n",
       " (0, 0, 0, 1): 0.30211312099999993,\n",
       " (0, 0, 1, 0): 0.220952887,\n",
       " (0, 0, 1, 1): 0.185551343,\n",
       " (0, 1, 0, 0): 0.20596030899999998,\n",
       " (0, 1, 0, 1): 0.3125728789999999,\n",
       " (0, 1, 1, 0): 0.16463311300000003,\n",
       " (0, 1, 1, 1): 0.20003465699999998,\n",
       " (1, 0, 0, 0): 0.24332230900000004,\n",
       " (1, 0, 0, 1): 0.144698879,\n",
       " (1, 0, 1, 0): 0.431095113,\n",
       " (1, 0, 1, 1): 0.26126065699999995,\n",
       " (1, 1, 0, 0): 0.14199169100000003,\n",
       " (1, 1, 0, 1): 0.240615121,\n",
       " (1, 1, 1, 0): 0.18331888699999996,\n",
       " (1, 1, 1, 1): 0.3531533429999999}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P_AB_giv_XY_dict = sample_bell_dist_det()\n",
    "P_AB_giv_XY_dict = sample_bell_dist_cond_prob()\n",
    "P_AB_giv_XY_dict\n",
    "\n",
    "\n",
    "# # make sure probability as expected for Bell \n",
    "# print(P_AB_giv_XY.sum() == 4.0, sum(P_AB_giv_XY_dict.values()) == 4)\n",
    "# print(abs(P_AB_giv_XY.sum() - 4.0)< 1e-06, abs(sum(P_AB_giv_XY_dict.values())-4.0) < 1e-06)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tools to manipulate from P_ABXY -> P_AB|XY or from joint prob to conditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to array form\n",
    "P_AB_giv_XY_arr = np.zeros((2,2,2,2))\n",
    "for a,b,x,y in np.ndindex(2,2,2,2):\n",
    "    # P_AB_giv_XY_arr[x][y][a][b] = P_AB_giv_XY_dict[(a,b,x,y)]\n",
    "    P_AB_giv_XY_arr[a,b,x,y] = P_AB_giv_XY_dict[(a,b,x,y)]\n",
    "\n",
    "# normalization check\n",
    "# sum(P_AB_giv_XY_dict.values()) == 4.0\n",
    "\n",
    "# # get P_AB|XY from P_ABXY\n",
    "# def P_AB_giv_XY(A,B, X, Y):\n",
    "#     P_ABXY = sum([P_ABXY_dict[(a,b,x,y)] for a,b,x,y in P_ABXY_dict if a==A and b==B and x==X and y==Y])\n",
    "#     P_AB = sum([P_ABXY_dict[(a,b,x,y)] for a,b,x,y in P_ABXY_dict if a==A and b==B])\n",
    "#     return P_ABXY/P_AB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Checking compatibility via deterministic strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnum_variables = len(all_strategies)  # num of W variables\\nA = np.zeros((num_variables, 16))\\n\\nfor i in range(num_variables):\\n    matrix = generate_top(i)\\n    flat_matrix = matrix.reshape(-1)\\n    # Position of 1s in the flattened matrix represents the coefficient for W[i] in each column of A\\n    A[i, :] = flat_matrix\\n\\n\\n# A*W[i] == internal_gurobi_expr\\nWs = sp.Matrix(16, 1, lambda i, _: sp.symbols(f'W_{i}'))\\n\\n# internal_gurobi_expr_sp = A * Ws\\nA * Ws\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "num_variables = len(all_strategies)  # num of W variables\n",
    "A = np.zeros((num_variables, 16))\n",
    "\n",
    "for i in range(num_variables):\n",
    "    matrix = generate_top(i)\n",
    "    flat_matrix = matrix.reshape(-1)\n",
    "    # Position of 1s in the flattened matrix represents the coefficient for W[i] in each column of A\n",
    "    A[i, :] = flat_matrix\n",
    "\n",
    "\n",
    "# A*W[i] == internal_gurobi_expr\n",
    "Ws = sp.Matrix(16, 1, lambda i, _: sp.symbols(f'W_{i}'))\n",
    "\n",
    "# internal_gurobi_expr_sp = A * Ws\n",
    "A * Ws\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-01-09\n",
      "Compatibility: 2 True\n"
     ]
    }
   ],
   "source": [
    "# Define the four functions\n",
    "## Bin(INT) -> Bin(INT)\n",
    "def identity(x):\n",
    "    return x\n",
    "def swap(x):\n",
    "    return 1-x\n",
    "def to0(_):\n",
    "    return 0\n",
    "def to1(_):\n",
    "    return 1\n",
    "\n",
    "basic_strategies = [identity, swap, to0, to1]\n",
    "all_strategies = list(itertools.product(basic_strategies, repeat=2))\n",
    "\n",
    "def generate_top(u):\n",
    "    f_u, g_u = all_strategies[u]\n",
    "    # value 1 at point(a,b) = (f_u(x),g_u(y)), zero everywhere else\n",
    "    def middle_entry(x,y):\n",
    "        # value 1 at (f_u(x),g_u(y)) zero everywhere else\n",
    "        middle = np.zeros((2,2), dtype=int)\n",
    "        middle[f_u(x), g_u(y)] = 1\n",
    "        return middle\n",
    "    top_level = np.array([\n",
    "                [middle_entry(0,0), middle_entry(0,1)], \n",
    "                [middle_entry(1,0), middle_entry(1,1)]\n",
    "                ]) \n",
    "    return top_level\n",
    "\n",
    "\n",
    "\n",
    "# declaring Gurobi variable W_i w/ i in {0,1,...,15}, and declaring v\n",
    "m1 = gp.Model(\"m1\")\n",
    "m1.setParam('OutputFlag', 0)\n",
    "W = m1.addVars(16, lb=0, ub=1, vtype=GRB.CONTINUOUS, name=\"W\")\n",
    "m1.update()\n",
    "global is_compatible\n",
    "\n",
    "internal_gurobi_expr = sum([W[i]*generate_top(i) for i in range(16)])\n",
    "m1.addConstr(W.sum() == 1, \"sum(W_i) == 1\")\n",
    "for x,y, a,b in itertools.product(range(2), repeat=4):\n",
    "    m1.addConstr(internal_gurobi_expr[x,y,a,b] == P_AB_giv_XY_dict[a,b,x,y], f\"P({a},{b}|{x},{y}) == {internal_gurobi_expr[x,y,a,b]} == {P_AB_giv_XY_dict[(a,b,x,y)]}\")\n",
    "m1.update()\n",
    "\n",
    "# m1.setParam('FeasibilityTol', 1e-4)\n",
    "# m1.setParam('OptimalityTol', 0.01)\n",
    "m1.optimize()\n",
    "\n",
    "if m1.status == 2: # GRB.OPTIMAL\n",
    "    is_compatible = True\n",
    "else: \n",
    "    is_compatible = False\n",
    "\n",
    "# assuming the distribution has weights 0 < w_i < 1\n",
    "print(\"Compatibility:\", m1.status, is_compatible)\n",
    "# if not is_compatible:\n",
    "#     raise SystemExit(\"DAG not compatible with given dist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Checking compatibility via structural equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asses_compat_with_card(P_AB_giv_XY_numeric: np.ndarray, card_l: int, verbose=0) -> bool:\n",
    "    m = gp.Model(\"m\")\n",
    "    m.reset()\n",
    "    m.setParam('OutputFlag', verbose)\n",
    "    m.params.NonConvex = 2 # Using quadratic equality constraints.\n",
    "\n",
    "\n",
    "    # variables\n",
    "    P_l = m.addMVar(card_l, vtype=GRB.CONTINUOUS, lb=0, ub=1, name=\"P_l\")\n",
    "    P_A_giv_X_l = m.addMVar(shape = (card_A, card_X, card_l), vtype=GRB.CONTINUOUS, name=\"P(A|X,l)\", lb=0, ub=1)\n",
    "    P_B_giv_Y_l = m.addMVar(shape = (card_B, card_Y, card_l), vtype=GRB.CONTINUOUS, name=\"P(B|Y,l)\", lb=0, ub=1)\n",
    "    P_BL_giv_Y = m.addMVar(shape = (card_B, card_Y, card_l), vtype=GRB.CONTINUOUS, name=\"P(B,l|Y)\", lb=0, ub=1)\n",
    "    m.update()\n",
    "\n",
    "    for b,y,l in np.ndindex(card_B, card_Y, card_l):\n",
    "        m.addConstr(P_BL_giv_Y[b,y,l] == P_B_giv_Y_l[b,y,l] * P_l[l], f\"prod[{b},{y},{l}] = P(B|Y,l) * P(l)\")\n",
    "\n",
    "    # structural eqn\n",
    "    for a,b,x,y in np.ndindex(card_A, card_B, card_X, card_Y):\n",
    "        m.addConstr(P_AB_giv_XY_numeric[a,b,x,y] == sum([P_A_giv_X_l[a,x,l] * P_BL_giv_Y[b,y,l]*P_l[l] for l in range(card_l)]), f\"eqn[{a},{b},{x},{y}]\")\n",
    "    m.update()\n",
    "\n",
    "\n",
    "    m.addConstr(sum([P_l[l] for l in range(card_l)]) == 1, \"sum_P_l = 1\")\n",
    "\n",
    "    for x, l in np.ndindex(card_X, card_l):\n",
    "        m.addConstr(sum([P_A_giv_X_l[a,x,l] for a in range(card_A)]) == 1, f'sum P(a|{x,l}) = 1')\n",
    "    for y, l in np.ndindex(card_Y, card_l):\n",
    "        m.addConstr(sum([P_B_giv_Y_l[b,y,l] for b in range(card_B)]) == 1, f'sum P(b|{y,l}) = 1')\n",
    "\n",
    "    # relaxing the equality constraint to a range\n",
    "    # m.setParam('FeasibilityTol', 1e-3)\n",
    "    # m.setParam('OptimalityTol', 1e-3)\n",
    "    # making the algorithm less sensitive to numerical issues\n",
    "    # m.setParam('ObjScale', -0.5)\n",
    "    # m.setParam('NumericFocus', 3)\n",
    "    # m.setParam('Presolve', 0)\n",
    "\n",
    "    m.optimize()\n",
    "    \n",
    "    if m.status == 2: # GRB.OPTIMAL\n",
    "        return True\n",
    "    else: \n",
    "        m.computeIIS()\n",
    "        # m.write(\"model.ilp\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB, norm\n",
    "\n",
    "class BellCompatible:\n",
    "    def __init__(self, card_A, card_B, card_X, card_Y, card_l, verbose=0): # settings and hidden common cause cardinality\n",
    "        self.card_A = card_A\n",
    "        self.card_B = card_B\n",
    "        self.card_X = card_X\n",
    "        self.card_Y = card_Y\n",
    "        self.card_l = card_l\n",
    "        self.verbose = verbose\n",
    "        self.model = None\n",
    "\n",
    "    def initialize_model(self):\n",
    "        self.model = gp.Model(\"BellCompat\")\n",
    "        self.model.reset()\n",
    "        self.model.setParam('OutputFlag', self.verbose)\n",
    "        self.model.params.NonConvex = 2 \n",
    "\n",
    "        # variables\n",
    "        self.P_l = self.model.addMVar(self.card_l, vtype=GRB.CONTINUOUS, lb=0, ub=1, name=\"P_l\")\n",
    "        self.P_A_giv_X_l = self.model.addMVar(shape=(self.card_A, self.card_X, self.card_l), vtype=GRB.CONTINUOUS, name=\"P(A|X,l)\", lb=0, ub=1)\n",
    "        self.P_B_giv_Y_l = self.model.addMVar(shape=(self.card_B, self.card_Y, self.card_l), vtype=GRB.CONTINUOUS, name=\"P(B|Y,l)\", lb=0, ub=1)\n",
    "        self.P_BL_giv_Y = self.model.addMVar(shape=(self.card_B, self.card_Y, self.card_l), vtype=GRB.CONTINUOUS, name=\"P(B,l|Y)\", lb=0, ub=1)\n",
    "        self.model.update()\n",
    "\n",
    "        # Adding constraints\n",
    "        for b, y, l in np.ndindex(self.card_B, self.card_Y, self.card_l):\n",
    "            self.model.addConstr(self.P_BL_giv_Y[b, y, l] == self.P_B_giv_Y_l[b, y, l] * self.P_l[l], f\"prod[{b},{y},{l}] = P(B|Y,l) * P(l)\")\n",
    "\n",
    "        for x, l in np.ndindex(self.card_X, self.card_l):\n",
    "            self.model.addConstr(sum([self.P_A_giv_X_l[a, x, l] for a in range(self.card_A)]) == 1, f'sum P(a|{x,l}) = 1')\n",
    "        for y, l in np.ndindex(self.card_Y, self.card_l):\n",
    "            self.model.addConstr(sum([self.P_B_giv_Y_l[b, y, l] for b in range(self.card_B)]) == 1, f'sum P(b|{y,l}) = 1')\n",
    "\n",
    "        self.model.addConstr(sum([self.P_l[l] for l in range(self.card_l)]) == 1, \"sum_P_l = 1\")\n",
    "\n",
    "    def is_compatible(self, P_AB_giv_XY_numeric):\n",
    "        self.initialize_model()\n",
    "\n",
    "        # structural equation\n",
    "        for a, b, x, y in np.ndindex(self.card_A, self.card_B, self.card_X, self.card_Y):\n",
    "            self.model.addConstr(P_AB_giv_XY_numeric[a, b, x, y] == sum([self.P_A_giv_X_l[a, x, l] * self.P_BL_giv_Y[b, y, l] for l in range(self.card_l)]), f\"eqn[{a},{b},{x},{y}]\")\n",
    "\n",
    "        self.model.update()\n",
    "        self.model.optimize()\n",
    "\n",
    "        if self.model.status == 2: # GRB.OPTIMAL\n",
    "            return True\n",
    "        else:\n",
    "            self.model.computeIIS()\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Finding minimal cardinality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = BellCompatible(2,2,2,2, card_l = 3, verbose=1)\n",
    "# model_feasibility = m.is_compatible(P_AB_giv_XY_dict)\n",
    "# print(\"Is this compatible w/ Bell DAG?\", model_feasibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarded solution information\n",
      "Set parameter NonConvex to value 2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'bool' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m card_l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_card_try\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      3\u001b[0m     m \u001b[38;5;241m=\u001b[39m BellCompatible(\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m2\u001b[39m, card_l, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     model_feasibility \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_compatible\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP_AB_giv_XY_arr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_feasibility \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[11], line 44\u001b[0m, in \u001b[0;36mBellCompatible.is_compatible\u001b[1;34m(self, P_AB_giv_XY_numeric)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# structural equation\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a, b, x, y \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcard_A, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcard_B, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcard_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcard_Y):\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddConstr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP_AB_giv_XY_numeric\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mP_A_giv_X_l\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mP_BL_giv_Y\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcard_l\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meqn[\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43ma\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mb\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43my\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39moptimize()\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\model.pxi:3790\u001b[0m, in \u001b[0;36mgurobipy.Model.addConstr\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'bool' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "max_card_try = 7 # maximum cardinality to try\n",
    "for card_l in range(max_card_try+1):\n",
    "    m = BellCompatible(2,2,2,2, card_l, verbose=1)\n",
    "    model_feasibility = m.is_compatible(P_AB_giv_XY_arr)\n",
    "    if model_feasibility == False:\n",
    "        continue\n",
    "    elif model_feasibility == True:\n",
    "        print(\"Bell DAG compatible with card_l:\", card_l)\n",
    "        break\n",
    "\n",
    "# For the dstribution:\n",
    "# P_AB_giv_XY_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P_AB_giv_XY_dict[0,0,1,1]  == P_AB_giv_XY_arr[0,0,1,1]\n",
    "\n",
    "m = BellCompatible(2,2,2,2, card_l, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarded solution information\n",
      "Set parameter NonConvex to value 2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'bool' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_compatible\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP_AB_giv_XY_arr\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 44\u001b[0m, in \u001b[0;36mBellCompatible.is_compatible\u001b[1;34m(self, P_AB_giv_XY_numeric)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# structural equation\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a, b, x, y \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcard_A, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcard_B, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcard_X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcard_Y):\n\u001b[1;32m---> 44\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddConstr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP_AB_giv_XY_numeric\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mP_A_giv_X_l\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mP_BL_giv_Y\u001b[49m\u001b[43m[\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcard_l\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meqn[\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43ma\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mb\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mx\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43my\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39moptimize()\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\model.pxi:3790\u001b[0m, in \u001b[0;36mgurobipy.Model.addConstr\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'bool' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "m.is_compatible(P_AB_giv_XY_arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
