{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import gurobipy as gp\n",
    "# from gurobipy import GRB\n",
    "# import networkx as nx\n",
    "\n",
    "# # [parent, child]\n",
    "# input_lst = [[\"X\", \"A\"], \n",
    "#              [\"l\", \"A\"], \n",
    "#              [\"l\", \"B\"], \n",
    "#              [\"Y\", \"B\"]]\n",
    "# hiddens_lst = [\"l\"]\n",
    "# cards_dict = {\"A\": 2, \"B\": 2, \"X\": 2, \"Y\": 2, \"l\": 3}\n",
    "\n",
    "\n",
    "# graph = nx.DiGraph()\n",
    "# graph.add_edges_from((parent, child) for parent, child in input_lst)\n",
    "    \n",
    "# # set cardinalities\n",
    "# cards_A, card_B, card_X, card_Y, card_l = 2,2,2,2,3\n",
    "\n",
    "\n",
    "# def get_mvar_shape(var):\n",
    "#     # returns tuple the product shape of var parents' cardinalities\n",
    "#     parents = list(graph.predecessors(var))\n",
    "#     return (var, *tuple(parents))\n",
    "\n",
    "\n",
    "# for var in list(graph):\n",
    "#     print(f'var {var}:', get_mvar_shape(var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(X_1, \\cdots , X_n) = \\prod_{i=1}^nP(X_i\\vert Pa(X_i))$$\n",
    "\n",
    "->\n",
    "$$P(X_1, \\cdots , X_k | P(X_{k+1}, \\cdots , X_n)) =\\sum_{\\lambda_1, ..., \\lambda_m} \\prod_{\\lambda_i \\in \\bm{\\lambda}} P(\\lambda_i | Pa(\\lambda_i)) \\prod_{X_i \\in \\bm{X}}P(X_i\\vert Pa(X_i))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class BellCompatible:\n",
    "#     def __init__(self, card_A, card_B, card_X, card_Y, card_l, verbose=0): # settings and hidden common cause cardinality\n",
    "#         self.card_A = card_A\n",
    "#         self.card_B = card_B\n",
    "#         self.card_X = card_X\n",
    "#         self.card_Y = card_Y\n",
    "#         self.card_l = card_l\n",
    "#         self.verbose = verbose\n",
    "#         self.model = None\n",
    "\n",
    "#     def initialize_model(self):\n",
    "#         self.model = gp.Model(\"BellCompat\")\n",
    "#         self.model.reset()\n",
    "#         self.model.setParam('OutputFlag', self.verbose)\n",
    "#         self.model.params.NonConvex = 2 \n",
    "\n",
    "#         # variables\n",
    "#         self.P_l = self.model.addMVar(self.card_l, vtype=GRB.CONTINUOUS, lb=0, ub=1, name=\"P_l\")\n",
    "#         self.P_A_giv_Xl = self.model.addMVar(shape=(self.card_A, self.card_X, self.card_l), vtype=GRB.CONTINUOUS, name=\"P(A|X,l)\", lb=0, ub=1)\n",
    "#         self.P_B_giv_Yl = self.model.addMVar(shape=(self.card_B, self.card_Y, self.card_l), vtype=GRB.CONTINUOUS, name=\"P(B|Y,l)\", lb=0, ub=1)\n",
    "#         self.prod = self.model.addMVar(shape=(self.card_B, self.card_l, self.card_Y), vtype=GRB.CONTINUOUS, name=\"P(B,l|Y)\", lb=0, ub=1)\n",
    "#         self.model.update()\n",
    "\n",
    "#         # constraints\n",
    "#         for b, y, l in np.ndindex(self.card_B, self.card_Y, self.card_l):\n",
    "#             # bc can't multiply 3 vars in SEM constraint\n",
    "#             self.model.addConstr(self.prod[b, l, y] == self.P_B_giv_Yl[b, y, l] * self.P_l[l], name=f\"P(B|Y,l) * P(l)\")\n",
    "\n",
    "#         for x, l in np.ndindex(self.card_X, self.card_l):\n",
    "#             self.model.addConstr(sum([self.P_A_giv_Xl[a, x, l] for a in range(self.card_A)]) == 1, name=f'sum P(a|{x,l}) = 1')\n",
    "#         for y, l in np.ndindex(self.card_Y, self.card_l):\n",
    "#             self.model.addConstr(sum([self.P_B_giv_Yl[b, y, l] for b in range(self.card_B)]) == 1, name=f'sum P(b|{y,l}) = 1')\n",
    "\n",
    "\n",
    "#         self.model.addConstr(sum([self.P_l[l] for l in range(self.card_l)]) == 1, \"sum_P_l = 1\")\n",
    "\n",
    "#     def is_compatible(self, P_AB_giv_XY): # P_AB_giv_XY array\n",
    "#         self.initialize_model()\n",
    "\n",
    "#         # structural equation\n",
    "#         for a, b, x, y in np.ndindex(self.card_A, self.card_B, self.card_X, self.card_Y):\n",
    "#             self.model.addConstr(P_AB_giv_XY[a, b, x, y] == sum([self.P_A_giv_Xl[a, x, l] * self.prod[b, l, y] for l in range(self.card_l)]), f\"P(A,B|X,Y) = sum_l P(A|X,l)*P(B|Y,l)*P(l)\")\n",
    "\n",
    "#         self.model.update()\n",
    "#         self.model.optimize()\n",
    "\n",
    "#         if self.model.status == 2: # GRB.OPTIMAL\n",
    "#             return True\n",
    "#         else:\n",
    "#             self.model.computeIIS()\n",
    "#             return False\n",
    "        \n",
    "\n",
    "# ## testing:\n",
    "# dist = np.random.rand(2,2,2,2)  # rand dist\n",
    "# m = BellCompatible(2,2,2,2, card_l = 3, verbose=1)\n",
    "# model_feasibility = m.is_compatible(dist)\n",
    "# print(\"Is this compatible w/ Bell DAG?\", model_feasibility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarded solution information\n",
      "dict_keys(['P_Z', 'P_A_giv_Z_l', 'P_l', 'P_B_giv_l', 'P_AB_giv_Z'])\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "class DAG_Dist_Compatibility:\n",
    "    def __init__(self, graph, hiddens_lst, cards_dict): \n",
    "        self.graph = nx.DiGraph()\n",
    "        self.graph.add_edges_from((parent, child) for parent, child in graph)\n",
    "        self.verbose = 0\n",
    "        self.hiddens_lst = hiddens_lst\n",
    "        self.cards = cards_dict\n",
    "        self.prob_vars = {}\n",
    "\n",
    "    def get_mvar_details(self, var):\n",
    "        parents = list(self.graph.predecessors(var))\n",
    "        # returns tuple(card_var, *card_parents(var)), \n",
    "        return (self.cards[var], *tuple(self.cards[parent] for parent in parents)), \"_\".join(parents)\n",
    "\n",
    "    def initialize_model(self):\n",
    "        self.model = gp.Model(\"DAG-Dist Compatibility\")\n",
    "        self.model.reset()\n",
    "        self.model.setParam('OutputFlag', self.verbose)\n",
    "        self.model.params.NonConvex = 2\n",
    "\n",
    "        ## variables\n",
    "        for var in list(self.graph.nodes):\n",
    "            shape, var_name = self.get_mvar_details(var)\n",
    "            if not var_name:\n",
    "                self.prob_vars[f'P_{var}'] = self.model.addMVar(shape=shape, vtype=GRB.CONTINUOUS, lb=0, ub=1, name=f'P_{var}')\n",
    "            else:\n",
    "                self.prob_vars[f'P_{var}_giv_{var_name}'] = self.model.addMVar(shape=shape, vtype=GRB.CONTINUOUS, lb=0, ub=1, name=f'P_{var}_giv_{var_name}')\n",
    "        self.model.update()\n",
    "\n",
    "    def markv_decomp_prod(self, coords, hidden_val):\n",
    "        vars_to_multiply = []\n",
    "        observable_indices = {var: idx for idx, var in enumerate(self.observables_lst)}\n",
    "\n",
    "        for var in self.graph.nodes:\n",
    "            if var in self.observables_lst:\n",
    "                vars_to_multiply.append(var)\n",
    "\n",
    "\n",
    "        # Reduce the list of variables to a single expression through auxiliary variables\n",
    "\n",
    "        # return vars_to_multiply[0] if vars_to_multiply else 1  # Return the final product or 1 if empty\n",
    "        return f\"SEM: {vars_to_multiply}\"\n",
    "\n",
    "\n",
    "\n",
    "    def get_joint(self):\n",
    "        self.observables_lst = [var for var in self.cards.keys() if var not in self.hiddens_lst]\n",
    "        self.childless = [node for node in self.graph.nodes if self.graph.out_degree(node) == 0]\n",
    "        self.given = [node for node in self.graph.nodes if node not in self.childless and node not in self.hiddens_lst]\n",
    "        self.target_joint_prob = \"\".join(self.childless) + \"_giv_\" + \"\".join(self.given)\n",
    "        self.observables_cards = tuple(self.cards[var] for var in self.observables_lst)\n",
    "        self.hidden_cards = tuple(self.cards[var] for var in self.hiddens_lst)\n",
    "        self.observable_combinations = itertools.product(*[range(card) for card in self.observables_cards])\n",
    "\n",
    "        self.prob_vars[f'P_{self.target_joint_prob}'] = self.model.addMVar(shape= self.observables_cards, vtype=GRB.CONTINUOUS, lb=0, ub=1, name=f'P_{self.target_joint_prob}')\n",
    "        self.model.update()\n",
    "        \n",
    "        # for a,b,x,y in np.ndindex(*tuple(self.observables_cards)): # <- generalize to any DAG by iterating through dictionary of observables\n",
    "        # print(f\"{self.prob_vars[f'P_{self.target_joint_prob}'][0,0,0,0]} == {sum([self.markv_decomp_prod((0,0,0,0), l) for l in range(self.hidden_cards[0])])}\")\n",
    "\n",
    "        # specific debugging:\n",
    "        # for a,b,z in np.ndindex(*tuple(self.observables_cards)):\n",
    "        #     # print(f\"{self.prob_vars[f'P_{self.target_joint_prob}'][a,b,z]} == {sum([self.markv_decomp_prod((a,b,z), l) for l in range(self.hidden_cards[0])])}\")\n",
    "        #     print(f\"{self.prob_vars[f'P_{self.target_joint_prob}'][a,b,z]} == {[self.markv_decomp_prod((a,b,z), l) for l in range(self.hidden_cards[0])]}\") \n",
    "        #     break\n",
    "        # print(self.markv_decomp_prod((0,0,0), 2))\n",
    "\n",
    "\n",
    "        # LHS would iterate through self.target_joint_pro, i.e. self.prob_vars[f'P_{self.target_joint_prob}']\n",
    "        cards_tmp = [self.cards[var] for var in self.observables_lst]\n",
    "\n",
    "        ## variables\n",
    "        sem_lst = []\n",
    "        sem_var_count = 0\n",
    "        print(self.prob_vars.keys())\n",
    "        for var in list(self.graph.nodes):\n",
    "            sem_var_count += 1\n",
    "            _, var_name = self.get_mvar_details(var)\n",
    "            if not var_name:\n",
    "                sem_lst.append(f'P_{var}')\n",
    "            else:\n",
    "                sem_lst.append(f'P_{var}_giv_{var_name}')\n",
    "        # print(    , sem_lst)\n",
    "\n",
    "        # make the sem_var_count variables less so that can multiply them\n",
    "        # iterate through cards_tmp\n",
    "\n",
    "        # for a,b,z in np.ndindex(*tuple(self.observables_cards)):\n",
    "        for comb in itertools.product(*[range(card) for card in cards_tmp]):\n",
    "\n",
    "            # print(f\"P_{self.target_joint_prob} == \\n{self.prob_vars[f'P_A_giv_Z_l'][0,0,0]} * {self.prob_vars[f'P_B_giv_l'][0,0]} * {self.prob_vars[f'P_Z'][0]}\")\n",
    "            # print(comb, f\"\"\"{self.prob_vars[f'P_{self.target_joint_prob}'][comb]} \n",
    "            #       == {self.prob_vars[f'P_A_giv_Z_l'][comb[0],comb[2],0]}\n",
    "            #       * {self.prob_vars[f'P_B_giv_l'][comb[1],0]} \n",
    "            #       * {self.prob_vars[f'P_Z'][0]} \n",
    "            #       * {self.prob_vars[f'P_l'][0]}\"\"\")\n",
    "            # # break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # print(comb, f\"\"\"{self.prob_vars[f'P_{self.target_joint_prob}'][comb]} \n",
    "            #       == [{[\n",
    "            #         self.prob_vars[f'P_A_giv_Z_l'][comb[0],comb[2],hidden1]\n",
    "            #         *\n",
    "            #         self.prob_vars[f'P_B_giv_l'][comb[1],hidden1]\n",
    "            #         *\n",
    "            #         self.prob_vars[f'P_Z'][hidden1]\n",
    "                                              \n",
    "            #            for hidden1 in range(self.hidden_cards[0])]}]\n",
    "            #       \"\"\")\n",
    "                  \n",
    "                #   {self.prob_vars[f'P_A_giv_Z_l'][comb[0],comb[2],0]}\n",
    "                #   * {self.prob_vars[f'P_B_giv_l'][comb[1],0]} \n",
    "                #   * {self.prob_vars[f'P_Z'][0]} \n",
    "                #   * {self.prob_vars[f'P_l'][0]}\"\"\")\n",
    "\n",
    "            break\n",
    "\n",
    "\n",
    "        # print(*tuple(self.observables_cards))\n",
    "\n",
    "\n",
    "# [parent, child]\n",
    "\n",
    "# input_lst = [[\"X\", \"A\"], [\"l\", \"A\"], [\"l\", \"B\"], [\"Y\", \"B\"]]\n",
    "# cards_dict = {\"A\": 2, \"B\": 2, \"X\": 2, \"Y\": 2, \"l\": 3}\n",
    "input_lst = [[\"Z\", \"A\"], [\"l\", \"A\"], [\"l\", \"B\"]]\n",
    "cards_dict = {\"A\": 2, \"B\": 2, \"Z\": 2, \"l\": 3}\n",
    "hiddens_lst = [\"l\"]\n",
    "\n",
    "\n",
    "example = DAG_Dist_Compatibility(input_lst, hiddens_lst, cards_dict)\n",
    "example.initialize_model()\n",
    "example.get_joint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discarded solution information\n",
      "var_key: P_Z, indices: ()\n",
      "var_key: P_A_giv_Z_l, indices: ()\n",
      "var_key: P_l, indices: ()\n",
      "var_key: P_B_giv_l, indices: (0,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (2,) and arg 1 with shape (2, 2, 3).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 140\u001b[0m\n\u001b[0;32m    138\u001b[0m example \u001b[38;5;241m=\u001b[39m DAG_Dist_Compatibility(input_lst, hiddens_lst, cards_dict)\n\u001b[0;32m    139\u001b[0m example\u001b[38;5;241m.\u001b[39minitialize_model()\n\u001b[1;32m--> 140\u001b[0m \u001b[43mexample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_joint\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 122\u001b[0m, in \u001b[0;36mDAG_Dist_Compatibility.get_joint\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# for a,b,x,y in np.ndindex(*tuple(self.observables_cards)): # <- generalize to any DAG by iterating through dictionary of observables\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m#     print(f\"{self.prob_vars[f'P_{self.target_joint_prob}'][0,0,0,0]} == {sum([self.markv_decomp_prod((0,0,0,0), l) for l in range(self.hidden_cards[0])])}\")\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# specific debugging:\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a,b,z \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndindex(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservables_cards)):\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# print(f\"{self.prob_vars[f'P_{self.target_joint_prob}'][a,b,z]} == {sum([self.markv_decomp_prod((a,b,z), l) for l in range(self.hidden_cards[0])])}\")\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprob_vars[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_joint_prob\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][a,b,z]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m == \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarkv_decomp_prod((a,b,z),\u001b[38;5;250m \u001b[39ml)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39ml\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_cards[\u001b[38;5;241m0\u001b[39m])]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 122\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# for a,b,x,y in np.ndindex(*tuple(self.observables_cards)): # <- generalize to any DAG by iterating through dictionary of observables\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m#     print(f\"{self.prob_vars[f'P_{self.target_joint_prob}'][0,0,0,0]} == {sum([self.markv_decomp_prod((0,0,0,0), l) for l in range(self.hidden_cards[0])])}\")\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# specific debugging:\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a,b,z \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndindex(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservables_cards)):\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# print(f\"{self.prob_vars[f'P_{self.target_joint_prob}'][a,b,z]} == {sum([self.markv_decomp_prod((a,b,z), l) for l in range(self.hidden_cards[0])])}\")\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprob_vars[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_joint_prob\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m][a,b,z]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m == \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmarkv_decomp_prod((a,b,z),\u001b[38;5;250m \u001b[39ml)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39ml\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_cards[\u001b[38;5;241m0\u001b[39m])]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 94\u001b[0m, in \u001b[0;36mDAG_Dist_Compatibility.markv_decomp_prod\u001b[1;34m(self, coords, hidden_val)\u001b[0m\n\u001b[0;32m     92\u001b[0m     aux_var_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maux_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprob_vars[aux_var_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39maddVar(vtype\u001b[38;5;241m=\u001b[39mGRB\u001b[38;5;241m.\u001b[39mCONTINUOUS, lb\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ub\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, name\u001b[38;5;241m=\u001b[39maux_var_name)\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39maddConstr(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprob_vars[aux_var_name] \u001b[38;5;241m==\u001b[39m \u001b[43mvars_to_multiply\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvars_to_multiply\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     95\u001b[0m     new_vars_to_multiply\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprob_vars[aux_var_name])\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\mvar.pxi:308\u001b[0m, in \u001b[0;36mgurobipy.MVar.__mul__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\mquadexpr.pxi:345\u001b[0m, in \u001b[0;36mgurobipy.MQuadExpr._from_mvar_times_mvar\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32msrc\\\\gurobipy\\\\util.pxi:90\u001b[0m, in \u001b[0;36mgurobipy._broadcast_shapes\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (2,) and arg 1 with shape (2, 2, 3)."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "class DAG_Dist_Compatibility:\n",
    "    def __init__(self, graph, hiddens_lst, cards_dict): \n",
    "        self.graph = nx.DiGraph()\n",
    "        self.graph.add_edges_from((parent, child) for parent, child in graph)\n",
    "        self.verbose = 0\n",
    "        self.hiddens_lst = hiddens_lst\n",
    "        self.cards = cards_dict\n",
    "        self.prob_vars = {}\n",
    "\n",
    "    def get_mvar_details(self, var):\n",
    "        parents = list(self.graph.predecessors(var))\n",
    "        # returns tuple(card_var, *card_parents(var)), \n",
    "        return (self.cards[var], *tuple(self.cards[parent] for parent in parents)), \"_\".join(parents)\n",
    "\n",
    "    def initialize_model(self):\n",
    "        self.model = gp.Model(\"DAG-Dist Compatibility\")\n",
    "        self.model.reset()\n",
    "        self.model.setParam('OutputFlag', self.verbose)\n",
    "        self.model.params.NonConvex = 2\n",
    "\n",
    "        ## variables\n",
    "        for var in list(self.graph.nodes):\n",
    "            shape, var_name = self.get_mvar_details(var)\n",
    "            if not var_name:\n",
    "                self.prob_vars[f'P_{var}'] = self.model.addMVar(shape=shape, vtype=GRB.CONTINUOUS, lb=0, ub=1, name=f'P_{var}')\n",
    "            else:\n",
    "                self.prob_vars[f'P_{var}_giv_{var_name}'] = self.model.addMVar(shape=shape, vtype=GRB.CONTINUOUS, lb=0, ub=1, name=f'P_{var}_giv_{var_name}')\n",
    "        self.model.update()\n",
    "\n",
    "    \"\"\"\n",
    "    def markv_decomp_prod(self, coords, hidden_val):\n",
    "        vars_to_multiply = []\n",
    "        for var in list(self.graph.nodes):\n",
    "            _, name = self.get_mvar_details(var)\n",
    "            if not name:\n",
    "                vars_to_multiply.append(self.prob_vars[f'P_{var}'][0])\n",
    "            else:\n",
    "                vars_to_multiply.append(self.prob_vars[f'P_{var}_giv_{name}'][0, 0, hidden_val])  # example index\n",
    "\n",
    "        while len(vars_to_multiply) > 1:\n",
    "            new_vars_to_multiply = []\n",
    "            for i in range(0, len(vars_to_multiply), 2):\n",
    "                if i+1 < len(vars_to_multiply):\n",
    "                    # create an auxiliary variable for each pair of variables\n",
    "                    aux_var_name = f'aux_{i//2}'\n",
    "                    self.prob_vars[aux_var_name] = self.model.addVar(vtype=GRB.CONTINUOUS, lb=0, ub=1, name=aux_var_name)\n",
    "                    self.model.addConstr(self.prob_vars[aux_var_name] == vars_to_multiply[i] * vars_to_multiply[i+1])\n",
    "                    new_vars_to_multiply.append(self.prob_vars[aux_var_name])\n",
    "                else:\n",
    "                    new_vars_to_multiply.append(vars_to_multiply[i])\n",
    "            vars_to_multiply = new_vars_to_multiply\n",
    "\n",
    "        return vars_to_multiply[0] if vars_to_multiply else 1  # Return the final product or 1 if empty\n",
    "    \"\"\"\n",
    "\n",
    "    def markv_decomp_prod(self, coords, hidden_val):\n",
    "        vars_to_multiply = []\n",
    "        observable_indices = {var: idx for idx, var in enumerate(self.observables_lst)}\n",
    "\n",
    "        for var in self.graph.nodes:\n",
    "            card, *parents = self.get_mvar_details(var)\n",
    "            # If no parents, access the unconditioned probability variable\n",
    "            if not parents:\n",
    "                vars_to_multiply.append(self.prob_vars[f'P_{var}'][0])  # assuming 1 dim distribution\n",
    "            else:\n",
    "                # Construct the index tuple from coords based on the parent names\n",
    "                indices = []\n",
    "                for parent in parents:\n",
    "                    if parent in observable_indices:  # Parent is an observable\n",
    "                        indices.append(coords[observable_indices[parent]])\n",
    "                    elif parent == self.hiddens_lst[0]:  # Assuming single hidden variable for simplicity\n",
    "                        indices.append(hidden_val)\n",
    "\n",
    "                # Ensure we use the right key for conditioned probabilities\n",
    "                parent_string = '_'.join(parents)\n",
    "                var_key = f'P_{var}_giv_{parent_string}' if parent_string else f'P_{var}'\n",
    "\n",
    "                print(f\"var_key: {var_key}, indices: {tuple(indices)}\")\n",
    "                vars_to_multiply.append(self.prob_vars[var_key][tuple(indices)])\n",
    "\n",
    "        # Reduce the list of variables to a single expression through auxiliary variables\n",
    "        while len(vars_to_multiply) > 1:\n",
    "            new_vars_to_multiply = []\n",
    "            for i in range(0, len(vars_to_multiply), 2):\n",
    "                if i + 1 < len(vars_to_multiply):\n",
    "                    aux_var_name = f'aux_{i // 2}'\n",
    "                    self.prob_vars[aux_var_name] = self.model.addVar(vtype=GRB.CONTINUOUS, lb=0, ub=1, name=aux_var_name)\n",
    "                    self.model.addConstr(self.prob_vars[aux_var_name] == vars_to_multiply[i] * vars_to_multiply[i + 1])\n",
    "                    new_vars_to_multiply.append(self.prob_vars[aux_var_name])\n",
    "                else:\n",
    "                    new_vars_to_multiply.append(vars_to_multiply[i])\n",
    "            vars_to_multiply = new_vars_to_multiply\n",
    "\n",
    "        return vars_to_multiply[0] if vars_to_multiply else 1  # Return the final product or 1 if empty\n",
    "\n",
    "\n",
    "\n",
    "    def get_joint(self):\n",
    "        self.observables_lst = [var for var in self.cards.keys() if var not in self.hiddens_lst]\n",
    "        self.childless = [node for node in self.graph.nodes if self.graph.out_degree(node) == 0]\n",
    "        self.given = [node for node in self.graph.nodes if node not in self.childless and node not in self.hiddens_lst]\n",
    "        self.target_joint_prob = \"\".join(self.childless) + \"_giv_\" + \"\".join(self.given)\n",
    "        self.observables_cards = tuple(self.cards[var] for var in self.observables_lst)\n",
    "        self.hidden_cards = tuple(self.cards[var] for var in self.hiddens_lst)\n",
    "        self.observable_combinations = itertools.product(*[range(card) for card in self.observables_cards])\n",
    "\n",
    "        self.prob_vars[f'P_{self.target_joint_prob}'] = self.model.addMVar(shape= self.observables_cards, vtype=GRB.CONTINUOUS, lb=0, ub=1, name=f'P_{self.target_joint_prob}')\n",
    "        self.model.update()\n",
    "        \n",
    "        # for a,b,x,y in np.ndindex(*tuple(self.observables_cards)): # <- generalize to any DAG by iterating through dictionary of observables\n",
    "        #     print(f\"{self.prob_vars[f'P_{self.target_joint_prob}'][0,0,0,0]} == {sum([self.markv_decomp_prod((0,0,0,0), l) for l in range(self.hidden_cards[0])])}\")\n",
    "\n",
    "        # specific debugging:\n",
    "        for a,b,z in np.ndindex(*tuple(self.observables_cards)):\n",
    "            # print(f\"{self.prob_vars[f'P_{self.target_joint_prob}'][a,b,z]} == {sum([self.markv_decomp_prod((a,b,z), l) for l in range(self.hidden_cards[0])])}\")\n",
    "            print(f\"{self.prob_vars[f'P_{self.target_joint_prob}'][a,b,z]} == {[self.markv_decomp_prod((a,b,z), l) for l in range(self.hidden_cards[0])]}\") \n",
    "            break\n",
    "        # print(self.markv_decomp_prod((0,0,0), 2))\n",
    "        # print(self.prob_vars.keys())\n",
    "        # print(self.prob_vars)\n",
    "\n",
    "\n",
    "# [parent, child]\n",
    "\n",
    "# input_lst = [[\"X\", \"A\"], [\"l\", \"A\"], [\"l\", \"B\"], [\"Y\", \"B\"]]\n",
    "# cards_dict = {\"A\": 2, \"B\": 2, \"X\": 2, \"Y\": 2, \"l\": 3}\n",
    "input_lst = [[\"Z\", \"A\"], [\"l\", \"A\"], [\"l\", \"B\"]]\n",
    "cards_dict = {\"A\": 2, \"B\": 2, \"Z\": 2, \"l\": 3}\n",
    "hiddens_lst = [\"l\"]\n",
    "\n",
    "\n",
    "example = DAG_Dist_Compatibility(input_lst, hiddens_lst, cards_dict)\n",
    "example.initialize_model()\n",
    "example.get_joint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
